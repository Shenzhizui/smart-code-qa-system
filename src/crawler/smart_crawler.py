#!/usr/bin/env python3
"""
æ™ºèƒ½GitHubçˆ¬å–å™¨ - é’ˆå¯¹å¤§å‹ä»“åº“ä¼˜åŒ–
"""

import time
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import logging
from .github_crawler import GitHubCrawler, GitHubIssue

logger = logging.getLogger(__name__)

class SmartGitHubCrawler(GitHubCrawler):
    """æ™ºèƒ½GitHubçˆ¬å–å™¨ï¼ˆç»§æ‰¿è‡ªåŸºç¡€çˆ¬å–å™¨ï¼‰"""
    
    def __init__(self, token: Optional[str] = None, 
                 request_delay: float = 0.5,
                 max_issues_per_repo: int = 100):
        """
        åˆå§‹åŒ–æ™ºèƒ½çˆ¬å–å™¨
        
        Args:
            max_issues_per_repo: æ¯ä¸ªä»“åº“æœ€å¤§Issueæ•°é‡
        """
        super().__init__(token, request_delay)
        self.max_issues_per_repo = max_issues_per_repo
    
    def get_issues_smart_sample(self, repo_name: str, 
                               sample_size: int = 50) -> List[GitHubIssue]:
        """
        æ™ºèƒ½æŠ½æ ·è·å–Issue
        
        ç­–ç•¥ï¼š
        1. è·å–æœ€è¿‘åˆ›å»ºçš„Issue
        2. è·å–è¯„è®ºæœ€å¤šçš„Issue
        3. è·å–ä¸åŒç±»å‹çš„Issueï¼ˆbug/featureç­‰ï¼‰
        """
        print(f"ğŸ“Š å¼€å§‹æ™ºèƒ½æŠ½æ ·è·å– {repo_name} çš„Issue...")
        print(f"   ç›®æ ‡æ ·æœ¬é‡: {sample_size}ä¸ª")
        
        all_samples = []
        
        # ç­–ç•¥1ï¼šè·å–æœ€è¿‘çš„Issueï¼ˆ30%ï¼‰
        recent_count = int(sample_size * 0.3)
        print(f"   ç­–ç•¥1: è·å–æœ€è¿‘ {recent_count} ä¸ªIssue...")
        recent_issues = self._get_recent_issues(repo_name, recent_count)
        all_samples.extend(recent_issues)
        
        # ç­–ç•¥2ï¼šè·å–è¯„è®ºæœ€å¤šçš„Issueï¼ˆ30%ï¼‰
        commented_count = int(sample_size * 0.3)
        print(f"   ç­–ç•¥2: è·å–è¯„è®ºæœ€å¤šçš„ {commented_count} ä¸ªIssue...")
        commented_issues = self._get_most_commented_issues(repo_name, commented_count)
        all_samples.extend(commented_issues)
        
        # ç­–ç•¥3ï¼šè·å–ç‰¹å®šæ ‡ç­¾çš„Issueï¼ˆ40%ï¼‰
        labeled_count = sample_size - len(all_samples)
        if labeled_count > 0:
            print(f"   ç­–ç•¥3: è·å–é‡è¦æ ‡ç­¾çš„ {labeled_count} ä¸ªIssue...")
            target_labels = ["bug", "enhancement", "documentation", "help wanted"]
            labeled_issues = self._get_issues_by_labels(repo_name, target_labels, labeled_count)
            all_samples.extend(labeled_issues)
        
        # å»é‡
        unique_issues = self._deduplicate_issues(all_samples)
        
        print(f"âœ… æ™ºèƒ½æŠ½æ ·å®Œæˆ: è·å– {len(unique_issues)} ä¸ªç‹¬ç‰¹Issue")
        return unique_issues[:sample_size]
    
    def _get_recent_issues(self, repo_name: str, limit: int) -> List[GitHubIssue]:
        """è·å–æœ€è¿‘çš„Issue"""
        try:
            repo = self.github.get_repo(repo_name)
            issues = repo.get_issues(state="all", sort="created", direction="desc")
            
            result = []
            count = 0
            
            for issue in issues:
                if count >= limit:
                    break
                
                if count > 0:
                    self._add_delay()
                
                result.append(self._convert_to_github_issue(issue))
                count += 1
            
            return result
            
        except Exception as e:
            logger.error(f"è·å–æœ€è¿‘Issueå¤±è´¥: {e}")
            return []
    
    def _get_most_commented_issues(self, repo_name: str, limit: int) -> List[GitHubIssue]:
        """è·å–è¯„è®ºæœ€å¤šçš„Issue"""
        try:
            repo = self.github.get_repo(repo_name)
            issues = repo.get_issues(state="all", sort="comments", direction="desc")
            
            result = []
            count = 0
            
            for issue in issues:
                if count >= limit:
                    break
                
                if count > 0:
                    self._add_delay()
                
                # åªå–æœ‰è¯„è®ºçš„
                if issue.comments > 0:
                    result.append(self._convert_to_github_issue(issue))
                    count += 1
            
            return result
            
        except Exception as e:
            logger.error(f"è·å–è¯„è®ºæœ€å¤šIssueå¤±è´¥: {e}")
            return []
    
    def _get_issues_by_labels(self, repo_name: str, 
                            target_labels: List[str], 
                            limit: int) -> List[GitHubIssue]:
        """æŒ‰æ ‡ç­¾è·å–Issue"""
        all_issues = []
        
        for label in target_labels:
            if len(all_issues) >= limit:
                break
                
            try:
                query = f"repo:{repo_name} label:{label} is:issue"
                search_results = self.github.search_issues(query)
                
                for issue in search_results:
                    if len(all_issues) >= limit:
                        break
                    
                    all_issues.append(self._convert_to_github_issue(issue))
                    self._add_delay()
                    
            except Exception as e:
                logger.warning(f"æœç´¢æ ‡ç­¾ {label} å¤±è´¥: {e}")
                continue
        
        return all_issues[:limit]
    
    def _convert_to_github_issue(self, issue) -> GitHubIssue:
        """è½¬æ¢PyGithub Issueå¯¹è±¡ä¸ºGitHubIssue"""
        body_content = issue.body or ""
        closed_at_str = str(issue.closed_at) if issue.closed_at else None
        is_pr = hasattr(issue, 'pull_request') and issue.pull_request
        
        return GitHubIssue(
            number=issue.number,
            title=issue.title,
            body=body_content,
            state=issue.state,
            created_at=str(issue.created_at),
            updated_at=str(issue.updated_at),
            closed_at=closed_at_str,
            user=issue.user.login if issue.user else "Unknown",
            assignees=[assignee.login for assignee in issue.assignees],
            labels=[label.name for label in issue.labels],
            comments=issue.comments,
            url=issue.html_url,
            is_pull_request=is_pr
        )
    
    def _deduplicate_issues(self, issues: List[GitHubIssue]) -> List[GitHubIssue]:
        """å»é‡Issueåˆ—è¡¨"""
        seen = set()
        unique_issues = []
        
        for issue in issues:
            if issue.number not in seen:
                seen.add(issue.number)
                unique_issues.append(issue)
        
        return unique_issues
    
    def analyze_large_repository(self, repo_name: str):
        """
        åˆ†æå¤§å‹ä»“åº“çš„Issueæ¦‚å†µ
        """
        print(f"\nğŸ“ˆ åˆ†æå¤§å‹ä»“åº“: {repo_name}")
        print("=" * 50)
        
        # 1. è·å–ä»“åº“åŸºæœ¬ä¿¡æ¯
        repo_info = self.get_repository_info(repo_name)
        if repo_info:
            print(f"ä»“åº“: {repo_info.full_name}")
            print(f"æè¿°: {repo_info.description}")
            print(f"Stars: {repo_info.stars}, Forks: {repo_info.forks}")
        
        # 2. è·å–å°‘é‡æ ·æœ¬è¿›è¡Œåˆ†æ
        print(f"\nğŸ” è·å–Issueæ ·æœ¬è¿›è¡Œåˆ†æ...")
        sample_issues = self.get_issues_smart_sample(repo_name, sample_size=30)
        
        if not sample_issues:
            print("âŒ æ— æ³•è·å–Issueæ ·æœ¬")
            return
        
        # 3. åˆ†ææ ·æœ¬
        total_issues = len(sample_issues)
        open_count = sum(1 for i in sample_issues if i.state == "open")
        closed_count = total_issues - open_count
        pr_count = sum(1 for i in sample_issues if i.is_pull_request)
        
        print(f"\nğŸ“Š æ ·æœ¬åˆ†æç»“æœ (åŸºäº {total_issues} ä¸ªæ ·æœ¬):")
        print(f"   å¼€å¯ç‡: {open_count/total_issues*100:.1f}%")
        print(f"   å…³é—­ç‡: {closed_count/total_issues*100:.1f}%")
        print(f"   PRæ¯”ä¾‹: {pr_count/total_issues*100:.1f}%")
        
        # è¯„è®ºåˆ†æ
        total_comments = sum(i.comments for i in sample_issues)
        avg_comments = total_comments / total_issues if total_issues > 0 else 0
        
        print(f"   å¹³å‡è¯„è®ºæ•°: {avg_comments:.1f}")
        
        # æ ‡ç­¾åˆ†æ
        all_labels = []
        for issue in sample_issues:
            all_labels.extend(issue.labels)
        
        if all_labels:
            label_counts = {}
            for label in all_labels:
                label_counts[label] = label_counts.get(label, 0) + 1
            
            top_labels = sorted(label_counts.items(), key=lambda x: x[1], reverse=True)[:5]
            print(f"   çƒ­é—¨æ ‡ç­¾: {', '.join([f'{label}({count})' for label, count in top_labels])}")
        
        # 4. ä¼°ç®—æ€»æ•°
        print(f"\nğŸ”® åŸºäºæ ·æœ¬ä¼°ç®—æ€»ä½“æƒ…å†µ:")
        
        # å‡è®¾æ ·æœ¬å…·æœ‰ä»£è¡¨æ€§ï¼Œä¼°ç®—æ€»ä½“è¯„è®ºæ•°
        estimated_total_comments = avg_comments * 2000 if avg_comments > 0 else 0
        print(f"   ä¼°ç®—æ€»è¯„è®ºæ•°: {estimated_total_comments:,.0f}")
        
        # å»ºè®®çš„å¤„ç†ç­–ç•¥
        print(f"\nğŸ’¡ å»ºè®®å¤„ç†ç­–ç•¥:")
        print(f"   1. ä½¿ç”¨æ™ºèƒ½æŠ½æ · (æ¨è {min(100, total_issues*3)} ä¸ªæ ·æœ¬)")
        print(f"   2. é‡ç‚¹å…³æ³¨æœ‰è¯„è®ºçš„Issue")
        print(f"   3. æŒ‰æ ‡ç­¾åˆ†ç±»å¤„ç†")
        print(f"   4. åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ¬¡å¤„ç†50-100ä¸ª")