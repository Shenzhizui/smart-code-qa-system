"""
æ–‡æœ¬åµŒå…¥æ¨¡å‹æ¨¡å— - æœ€ç»ˆç‰ˆ
ä½¿ç”¨ sentence-transformers åº“
"""
import os
import sys
from typing import List, Union
import numpy as np
from sentence_transformers import SentenceTransformer

# ============ å…³é”®è®¾ç½®ï¼šå¼ºåˆ¶ä½¿ç”¨é•œåƒæº ============
# å¿…é¡»åœ¨å¯¼å…¥ä»»ä½• huggingface ç›¸å…³æ¨¡å—ä¹‹å‰è®¾ç½®
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# å¦‚æœéœ€è¦ä»£ç†ï¼Œå¯ä»¥åœ¨è¿™é‡Œè®¾ç½®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
# os.environ['HTTP_PROXY'] = 'http://127.0.0.1:7890'
# os.environ['HTTPS_PROXY'] = 'http://127.0.0.1:7890'

print(f"ğŸ”§ åµŒå…¥æ¨¡å‹è®¾ç½®: HF_ENDPOINT={os.environ.get('HF_ENDPOINT')}")


class TextEmbeddingModel:
    """æ–‡æœ¬åµŒå…¥æ¨¡å‹ç±»"""
    
    def __init__(self, model_name: str = "paraphrase-MiniLM-L3-v2"):
        """
        åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨å°å‹è‹±æ–‡æ¨¡å‹
        """
        self.model_name = model_name
        
        print(f"ğŸ”§ æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹: {model_name}")
        print(f"   ä½¿ç”¨é•œåƒæº: {os.environ.get('HF_ENDPOINT', 'é»˜è®¤')}")
        
        try:
            # åŠ è½½æ¨¡å‹ï¼ŒæŒ‡å®šç¼“å­˜ç›®å½•
            self.model = SentenceTransformer(
                model_name,
                cache_folder="./models",  # æœ¬åœ°ç¼“å­˜ç›®å½•
                device='cpu'  # ä½¿ç”¨CPU
            )
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
            
            # æµ‹è¯•æ¨¡å‹è·å–ç»´åº¦
            test_embedding = self.model.encode(["æµ‹è¯•æ–‡æœ¬"])
            self.dimensions = test_embedding.shape[1]
            print(f"âœ… åµŒå…¥ç»´åº¦: {self.dimensions}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("\nğŸ”„ æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½...")
            
            # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²åœ¨ç¼“å­˜ä¸­
            model_path = f"./models/models--sentence-transformers--{model_name.replace('/', '--')}"
            if os.path.exists(model_path):
                print(f"âœ… å‘ç°æœ¬åœ°ç¼“å­˜æ¨¡å‹: {model_path}")
                print("ğŸ”„ å°è¯•ä»æœ¬åœ°ç¼“å­˜åŠ è½½...")
                try:
                    # å°è¯•ä»æœ¬åœ°è·¯å¾„åŠ è½½
                    self.model = SentenceTransformer(model_path, device='cpu')
                    test_embedding = self.model.encode(["æµ‹è¯•æ–‡æœ¬"])
                    self.dimensions = test_embedding.shape[1]
                    print(f"âœ… ä»æœ¬åœ°ç¼“å­˜åŠ è½½æˆåŠŸï¼")
                    print(f"âœ… åµŒå…¥ç»´åº¦: {self.dimensions}")
                    return
                except Exception as e2:
                    print(f"âŒ æœ¬åœ°ç¼“å­˜åŠ è½½å¤±è´¥: {e2}")
            
            print("ğŸ”„ åˆ›å»ºç¦»çº¿å›é€€æ¨¡å‹...")
            self._create_fallback_model()
    
    def _create_fallback_model(self):
        """åˆ›å»ºç¦»çº¿å›é€€æ¨¡å‹"""
        print("âš ï¸ ä½¿ç”¨å›é€€æ¨¡å‹ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰")
        
        class FallbackModel:
            def __init__(self, dim=384):
                self.dim = dim
                import numpy as np
                self.np = np
            
            def encode(self, texts, **kwargs):
                if isinstance(texts, str):
                    texts = [texts]
                
                embeddings = []
                for text in texts:
                    # åŸºäºæ–‡æœ¬çš„ç¡®å®šæ€§ä¼ªéšæœºå‘é‡
                    import hashlib
                    seed = int(hashlib.md5(text.encode()).hexdigest()[:8], 16)
                    self.np.random.seed(seed)
                    vec = self.np.random.randn(self.dim)
                    # å½’ä¸€åŒ–
                    norm = self.np.linalg.norm(vec)
                    if norm > 0:
                        vec = vec / norm
                    embeddings.append(vec)
                
                return self.np.array(embeddings)
        
        self.model = FallbackModel(384)
        self.dimensions = 384
        self.model_name = "fallback-offline-model"
        print("âœ… å›é€€æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    
    def get_embedding(self, text: str) -> np.ndarray:
        """è·å–å•ä¸ªæ–‡æœ¬çš„åµŒå…¥å‘é‡"""
        return self.model.encode(text)
    
    def get_embeddings(self, texts: List[str]) -> np.ndarray:
        """è·å–å¤šä¸ªæ–‡æœ¬çš„åµŒå…¥å‘é‡"""
        return self.model.encode(texts)
    
    def compute_similarity(self, query: str, sentences: List[str]) -> List[float]:
        """è®¡ç®—ç›¸ä¼¼åº¦"""
        query_embedding = self.get_embedding(query)
        sentence_embeddings = self.get_embeddings(sentences)
        
        similarities = []
        query_norm = np.linalg.norm(query_embedding)
        
        for emb in sentence_embeddings:
            sentence_norm = np.linalg.norm(emb)
            if query_norm > 0 and sentence_norm > 0:
                similarity = np.dot(query_embedding, emb) / (query_norm * sentence_norm)
                similarities.append(float(similarity))
            else:
                similarities.append(0.0)
        
        return similarities


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•åµŒå…¥æ¨¡å‹...")
    embedder = TextEmbeddingModel()
    
    # æµ‹è¯•ä¸­æ–‡æ–‡æœ¬
    texts = ["Pythonç¼–ç¨‹è¯­è¨€", "å‘é‡æ•°æ®åº“ChromaDB", "å¤§å‹è¯­è¨€æ¨¡å‹LLM"]
    embeddings = embedder.get_embeddings(texts)
    
    print(f"âœ… æ¨¡å‹: {embedder.model_name}")
    print(f"âœ… ç»´åº¦: {embedder.dimensions}")
    print(f"âœ… æµ‹è¯•æ–‡æœ¬: {texts}")
    print(f"âœ… åµŒå…¥å½¢çŠ¶: {embeddings.shape}")