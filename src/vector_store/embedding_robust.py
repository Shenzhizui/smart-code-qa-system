"""
å¥å£®çš„åµŒå…¥æ¨¡å‹ - è‡ªåŠ¨å¤„ç†ç½‘ç»œé—®é¢˜
"""
import os
import sys
from typing import List, Union
import numpy as np

# å¼ºåˆ¶è®¾ç½®é•œåƒæº
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

class RobustEmbeddingModel:
    """å¥å£®çš„åµŒå…¥æ¨¡å‹ï¼Œè‡ªåŠ¨å¤„ç†å„ç§å¼‚å¸¸"""
    
    def __init__(self, model_name: str = None):
        """
        åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°æˆ–è·¯å¾„ï¼ŒNoneåˆ™è‡ªåŠ¨é€‰æ‹©
        """
        self.model = None
        self.model_name = model_name or self._select_best_model()
        self.dimensions = 384  # é»˜è®¤ç»´åº¦
        
        print(f"ğŸ”§ åˆå§‹åŒ–åµŒå…¥æ¨¡å‹: {self.model_name}")
        
        try:
            self._load_model()
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("ğŸ”„ åˆ›å»ºç¦»çº¿å›é€€æ¨¡å‹...")
            self._create_fallback_model()
    
    def _select_best_model(self):
        """é€‰æ‹©æœ€ä½³å¯ç”¨æ¨¡å‹"""
        # ä¼˜å…ˆçº§ï¼šæœ¬åœ°æ¨¡å‹ > å°å‹æ¨¡å‹ > ä¸­æ–‡æ¨¡å‹
        local_models = [
            "./models/paraphrase-MiniLM-L3-v2",
            "./models/text2vec-base-chinese", 
            "./models/minimal_model"
        ]
        
        import os
        for model_path in local_models:
            if os.path.exists(model_path):
                print(f"âœ… å‘ç°æœ¬åœ°æ¨¡å‹: {model_path}")
                return model_path
        
        # æ²¡æœ‰æœ¬åœ°æ¨¡å‹ï¼Œé€‰æ‹©å°å‹åœ¨çº¿æ¨¡å‹
        return "paraphrase-MiniLM-L3-v2"
    
    def _load_model(self):
        """åŠ è½½æ¨¡å‹"""
        from sentence_transformers import SentenceTransformer
        
        print(f"ğŸ“¥ æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_name}")
        
        # è®¾ç½®é‡è¯•å’Œè¶…æ—¶
        import requests
        import urllib3
        
        # ç¦ç”¨è­¦å‘Š
        urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
        
        # åŠ è½½æ¨¡å‹
        self.model = SentenceTransformer(
            self.model_name,
            cache_folder="./models",
            device='cpu'
        )
        
        # æµ‹è¯•è·å–ç»´åº¦
        test_embedding = self.model.encode(["test"])
        self.dimensions = test_embedding.shape[1]
        
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        print(f"âœ… åµŒå…¥ç»´åº¦: {self.dimensions}")
    
    def _create_fallback_model(self):
        """åˆ›å»ºå›é€€æ¨¡å‹"""
        print("âš ï¸ ä½¿ç”¨å›é€€æ¨¡å‹ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰")
        
        class FallbackModel:
            def __init__(self, dim=384):
                self.dim = dim
                import numpy as np
                self.np = np
            
            def encode(self, texts, **kwargs):
                if isinstance(texts, str):
                    texts = [texts]
                
                embeddings = []
                for text in texts:
                    # åŸºäºæ–‡æœ¬çš„ç¡®å®šæ€§ä¼ªéšæœºå‘é‡
                    import hashlib
                    seed = int(hashlib.md5(text.encode()).hexdigest()[:8], 16)
                    self.np.random.seed(seed)
                    vec = self.np.random.randn(self.dim)
                    # å½’ä¸€åŒ–
                    norm = self.np.linalg.norm(vec)
                    if norm > 0:
                        vec = vec / norm
                    embeddings.append(vec)
                
                return self.np.array(embeddings)
        
        self.model = FallbackModel(384)
        self.dimensions = 384
        self.model_name = "fallback-offline-model"
    
    def get_embedding(self, text: str) -> np.ndarray:
        """è·å–å•ä¸ªæ–‡æœ¬åµŒå…¥"""
        return self.model.encode(text)
    
    def get_embeddings(self, texts: List[str]) -> np.ndarray:
        """è·å–æ‰¹é‡æ–‡æœ¬åµŒå…¥"""
        return self.model.encode(texts)
    
    def compute_similarity(self, query: str, sentences: List[str]) -> List[float]:
        """è®¡ç®—ç›¸ä¼¼åº¦"""
        query_embedding = self.get_embedding(query)
        sentence_embeddings = self.get_embeddings(sentences)
        
        similarities = []
        query_norm = np.linalg.norm(query_embedding)
        
        for emb in sentence_embeddings:
            sentence_norm = np.linalg.norm(emb)
            if query_norm > 0 and sentence_norm > 0:
                similarity = np.dot(query_embedding, emb) / (query_norm * sentence_norm)
                similarities.append(float(similarity))
            else:
                similarities.append(0.0)
        
        return similarities

# ä¸»å‡½æ•°ï¼šæµ‹è¯•æ¨¡å‹
def test_robust_model():
    """æµ‹è¯•å¥å£®æ¨¡å‹"""
    print("ğŸ§ª æµ‹è¯•å¥å£®åµŒå…¥æ¨¡å‹")
    print("=" * 50)
    
    model = RobustEmbeddingModel()
    
    # æµ‹è¯•
    texts = ["hello world", "this is a test", "vector database"]
    embeddings = model.get_embeddings(texts)
    
    print(f"âœ… æ¨¡å‹åç§°: {model.model_name}")
    print(f"âœ… åµŒå…¥ç»´åº¦: {model.dimensions}")
    print(f"âœ… æ‰¹é‡å¤„ç†: {len(texts)} ä¸ªæ–‡æœ¬")
    print(f"âœ… åµŒå…¥å½¢çŠ¶: {embeddings.shape}")
    
    # æµ‹è¯•ç›¸ä¼¼åº¦
    query = "test world"
    sentences = ["hello world", "database test", "unrelated topic"]
    
    similarities = model.compute_similarity(query, sentences)
    
    print(f"\nâœ… ç›¸ä¼¼åº¦æµ‹è¯•:")
    print(f"   æŸ¥è¯¢: '{query}'")
    for i, (sentence, sim) in enumerate(zip(sentences, similarities), 1):
        print(f"   å¥å­{i}: '{sentence}' - ç›¸ä¼¼åº¦: {sim:.4f}")
    
    return model

if __name__ == "__main__":
    test_robust_model()