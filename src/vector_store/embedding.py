"""
æ–‡æœ¬åµŒå…¥æ¨¡å‹æ¨¡å—
ä½¿ç”¨ sentence-transformers åº“ï¼Œæ”¯æŒç¦»çº¿æ¨¡å¼å’Œé•œåƒæº
"""
import os
import sys
from typing import List, Union
import numpy as np

# ============ å…³é”®è®¾ç½®ï¼šå¼ºåˆ¶ä½¿ç”¨é•œåƒæº ============
# å¿…é¡»åœ¨å¯¼å…¥ä»»ä½• huggingface ç›¸å…³æ¨¡å—ä¹‹å‰è®¾ç½®
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„ï¼Œç¡®ä¿å¯ä»¥å¯¼å…¥å…¶ä»–æ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    print("  sentence-transformers ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç¦»çº¿æ¨¡å¼")


class TextEmbeddingModel:
    """æ–‡æœ¬åµŒå…¥æ¨¡å‹ç±»"""
    
    def __init__(self, model_name: str = "paraphrase-MiniLM-L3-v2"):
        """
        åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œé»˜è®¤ä½¿ç”¨å°å‹è‹±æ–‡æ¨¡å‹
                        ä¹Ÿå¯ä»¥ä½¿ç”¨ï¼š
                        - 'BAAI/bge-small-zh' (ä¸­æ–‡ä¼˜åŒ–)
                        - 'all-MiniLM-L6-v2' (è‹±æ–‡)
                        - 'paraphrase-multilingual-MiniLM-L12-v2' (å¤šè¯­è¨€)
        """
        self.model_name = model_name
        
        print(f"ğŸ”§ æ­£åœ¨åŠ è½½åµŒå…¥æ¨¡å‹: {model_name}")
        print(f"   ä½¿ç”¨é•œåƒæº: {os.environ.get('HF_ENDPOINT', 'é»˜è®¤')}")
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åœ¨æœ¬åœ°ç¼“å­˜ä¸­
        self._check_local_cache()
        
        try:
            if SENTENCE_TRANSFORMERS_AVAILABLE:
                # å°è¯•åŠ è½½æ¨¡å‹
                self.model = SentenceTransformer(
                    model_name,
                    cache_folder="./models",
                    device='cpu'
                )
                print(f"  æ¨¡å‹åŠ è½½æˆåŠŸï¼")
                
                # æµ‹è¯•è·å–ç»´åº¦
                test_embedding = self.model.encode(["æµ‹è¯•æ–‡æœ¬"])
                self.dimensions = test_embedding.shape[1]
                print(f"  åµŒå…¥ç»´åº¦: {self.dimensions}")
            else:
                raise ImportError("sentence-transformers æœªå®‰è£…")
                
        except Exception as e:
            print(f"  æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("\n åˆ›å»ºç¦»çº¿å›é€€æ¨¡å‹...")
            self._create_fallback_model()
    
    def _check_local_cache(self):
        """æ£€æŸ¥æœ¬åœ°æ¨¡å‹ç¼“å­˜"""
        cache_dir = "./models"
        if os.path.exists(cache_dir):
            # æ£€æŸ¥æ˜¯å¦æœ‰å·²ä¸‹è½½çš„æ¨¡å‹
            import glob
            model_pattern = f"models--sentence-transformers--{self.model_name.replace('/', '--')}"
            model_path = os.path.join(cache_dir, model_pattern)
            
            if os.path.exists(model_path):
                print(f"  å‘ç°æœ¬åœ°ç¼“å­˜æ¨¡å‹: {model_path}")
                return model_path
            else:
                print(f"  æœ¬åœ°ç¼“å­˜ä¸­æ²¡æœ‰æ¨¡å‹: {self.model_name}")
        else:
            print(f"  æ¨¡å‹ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {cache_dir}")
            os.makedirs(cache_dir, exist_ok=True)
            print(f"  å·²åˆ›å»ºç¼“å­˜ç›®å½•: {cache_dir}")
        
        return None
    
    def _create_fallback_model(self):
        """åˆ›å»ºç¦»çº¿å›é€€æ¨¡å‹"""
        print(" ä½¿ç”¨å›é€€æ¨¡å‹ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰")
        
        class FallbackModel:
            def __init__(self, dim=384):
                self.dim = dim
                import numpy as np
                self.np = np
            
            def encode(self, texts, **kwargs):
                if isinstance(texts, str):
                    texts = [texts]
                
                embeddings = []
                for text in texts:
                    # åŸºäºæ–‡æœ¬çš„ç¡®å®šæ€§ä¼ªéšæœºå‘é‡
                    import hashlib
                    seed = int(hashlib.md5(text.encode()).hexdigest()[:8], 16)
                    self.np.random.seed(seed)
                    vec = self.np.random.randn(self.dim)
                    # å½’ä¸€åŒ–
                    norm = self.np.linalg.norm(vec)
                    if norm > 0:
                        vec = vec / norm
                    embeddings.append(vec)
                
                return self.np.array(embeddings)
        
        self.model = FallbackModel(384)
        self.dimensions = 384
        self.model_name = "fallback-offline-model"
        print("  å›é€€æ¨¡å‹åˆ›å»ºæˆåŠŸ")
    
    def get_embedding(self, text: str) -> np.ndarray:
        """
        è·å–å•ä¸ªæ–‡æœ¬çš„åµŒå…¥å‘é‡
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            åµŒå…¥å‘é‡
        """
        return self.model.encode(text)
    
    def get_embeddings(self, texts: List[str]) -> np.ndarray:
        """
        è·å–å¤šä¸ªæ–‡æœ¬çš„åµŒå…¥å‘é‡
        
        Args:
            texts: è¾“å…¥æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            åµŒå…¥å‘é‡çŸ©é˜µ
        """
        return self.model.encode(texts)
    
    def compute_similarity(self, query: str, sentences: List[str]) -> List[float]:
        """
        è®¡ç®—æŸ¥è¯¢æ–‡æœ¬ä¸å¤šä¸ªå¥å­çš„ç›¸ä¼¼åº¦
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            sentences: å¥å­åˆ—è¡¨
            
        Returns:
            ç›¸ä¼¼åº¦åˆ—è¡¨
        """
        # è·å–åµŒå…¥
        query_embedding = self.get_embedding(query)
        sentence_embeddings = self.get_embeddings(sentences)
        
        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        similarities = []
        query_norm = np.linalg.norm(query_embedding)
        
        for emb in sentence_embeddings:
            sentence_norm = np.linalg.norm(emb)
            if query_norm > 0 and sentence_norm > 0:
                similarity = np.dot(query_embedding, emb) / (query_norm * sentence_norm)
                similarities.append(float(similarity))
            else:
                similarities.append(0.0)
        
        return similarities


# æµ‹è¯•å‡½æ•°
def test_embedding_model():
    """æµ‹è¯•åµŒå…¥æ¨¡å‹"""
    print(" æµ‹è¯•åµŒå…¥æ¨¡å‹")
    print("=" * 60)
    
    try:
        embedder = TextEmbeddingModel()
        
        # æµ‹è¯•ä¸­æ–‡æ–‡æœ¬
        texts = ["Pythonç¼–ç¨‹è¯­è¨€", "å‘é‡æ•°æ®åº“ChromaDB", "å¤§å‹è¯­è¨€æ¨¡å‹LLM"]
        embeddings = embedder.get_embeddings(texts)
        
        print(f"  æ¨¡å‹: {embedder.model_name}")
        print(f"  ç»´åº¦: {embedder.dimensions}")
        print(f"  æµ‹è¯•æ–‡æœ¬: {texts}")
        print(f"  åµŒå…¥å½¢çŠ¶: {embeddings.shape}")
        
        # æµ‹è¯•ç›¸ä¼¼åº¦
        query = "ç¼–ç¨‹è¯­è¨€Python"
        similarities = embedder.compute_similarity(query, texts)
        
        print(f"\n  ç›¸ä¼¼åº¦æµ‹è¯•:")
        print(f"   æŸ¥è¯¢: '{query}'")
        for text, sim in zip(texts, similarities):
            print(f"   '{text}': {sim:.4f}")
        
        return True
        
    except Exception as e:
        print(f"  æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_embedding_model():
    """æµ‹è¯•åµŒå…¥æ¨¡å‹ - ä¾›å¤–éƒ¨è°ƒç”¨"""
    print(" æµ‹è¯•åµŒå…¥æ¨¡å‹ï¼ˆå¤–éƒ¨è°ƒç”¨ï¼‰")
    print("=" * 50)
    
    try:
        embedder = TextEmbeddingModel()
        
        print(f"  æ¨¡å‹: {embedder.model_name}")
        print(f"  ç»´åº¦: {embedder.dimensions}")
        
        # æµ‹è¯•åŸºæœ¬åŠŸèƒ½
        texts = ["æµ‹è¯•æ–‡æœ¬1", "æµ‹è¯•æ–‡æœ¬2", "æµ‹è¯•æ–‡æœ¬3"]
        embeddings = embedder.get_embeddings(texts)
        
        print(f"  æ‰¹é‡å¤„ç† {len(texts)} ä¸ªæ–‡æœ¬")
        print(f"  åµŒå…¥å½¢çŠ¶: {embeddings.shape}")
        
        # æµ‹è¯•ç›¸ä¼¼åº¦
        query = "æµ‹è¯•"
        similarities = embedder.compute_similarity(query, texts)
        
        print(f"  æŸ¥è¯¢: '{query}'")
        for i, (text, sim) in enumerate(zip(texts, similarities), 1):
            print(f"   æ–‡æœ¬{i}: '{text}' - ç›¸ä¼¼åº¦: {sim:.4f}")
        
        print("\n  åµŒå…¥æ¨¡å‹æµ‹è¯•å®Œæˆï¼")
        return True
        
    except Exception as e:
        print(f"  æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


# åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ å¯¼å‡º
__all__ = ["TextEmbeddingModel", "test_embedding_model"]

if __name__ == "__main__":
    test_embedding_model()